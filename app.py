import streamlit as st
from llm import ChatBot
from langchain_core.messages import HumanMessage, AIMessage

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI èŠå¤©åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="centered"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "chatbot" not in st.session_state:
    st.session_state.chatbot = ChatBot()
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡µé¢æ ‡é¢˜
st.title("ğŸ¤– AI èŠå¤©åŠ©æ‰‹")

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # è·å–AIå“åº”
    with st.chat_message("assistant"):
        try:
            # åˆ›å»ºä¸€ä¸ªç©ºçš„å ä½ç¬¦
            message_placeholder = st.empty()
            full_response = ""
            
            # æµå¼è·å–å“åº”
            for chunk in st.session_state.chatbot.chat_stream(prompt):
                full_response += chunk
                # æ›´æ–°å ä½ç¬¦å†…å®¹
                message_placeholder.markdown(full_response + "â–Œ")
            
            # æœ€ç»ˆæ›´æ–°ï¼Œç§»é™¤å…‰æ ‡
            message_placeholder.markdown(full_response)
            
            # æ·»åŠ AIå“åº”åˆ°èŠå¤©å†å²
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
            st.session_state.messages.pop()  # ç§»é™¤å¤±è´¥çš„ç”¨æˆ·æ¶ˆæ¯ 