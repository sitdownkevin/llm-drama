import streamlit as st
from llm import state_generation_chain, guiding_questions_chain, story_generation_chain, GeneratedStates, GuidedQuestions, QuestionWithOptions, FinalStory # ä¿®æ”¹: å¯¼å…¥æ–°å†…å®¹
import asyncio
from langchain.chat_models import ChatOpenAI

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="æ— é™å†’é™©å‰§æœ¬ç”Ÿæˆå™¨", layout="wide")

st.title("ğŸ² æ— é™å†’é™©å‰§æœ¬ç”Ÿæˆå™¨")
st.caption("æ ¹æ®éšæœºç”Ÿæˆçš„èµ·ç‚¹å’Œç»ˆç‚¹ï¼Œé€šè¿‡ä¸€ç³»åˆ—é€‰æ‹©æ¥æ„å»ºä½ è‡ªå·±çš„å†’é™©æ•…äº‹ï¼")

# åˆå§‹åŒ– session state
if 'initial_state' not in st.session_state:
    st.session_state.initial_state = ""
if 'final_state' not in st.session_state:
    st.session_state.final_state = ""
if 'guided_questions' not in st.session_state:
    st.session_state.guided_questions = [] # List[QuestionWithOptions]
if 'user_choices' not in st.session_state:
    st.session_state.user_choices = {} # Dict[str, str] e.g. {"user_choice_0": "selected_option_for_q0"}
if 'final_story' not in st.session_state: # æ–°å¢
    st.session_state.final_story = ""
if 'story_generated' not in st.session_state:
    st.session_state.story_generated = False
if 'questions_generated' not in st.session_state:
    st.session_state.questions_generated = False

async def generate_states_and_questions():
    """ç”Ÿæˆåˆå§‹/ç»“æŸçŠ¶æ€ï¼Œç„¶åç”Ÿæˆå¼•å¯¼é—®é¢˜"""
    try:
        # é‡ç½®çŠ¶æ€
        st.session_state.initial_state = ""
        st.session_state.final_state = ""
        st.session_state.guided_questions = []
        st.session_state.user_choices = {}
        st.session_state.final_story = ""
        st.session_state.story_generated = False
        st.session_state.questions_generated = False

        with st.spinner("æ­£åœ¨ç”Ÿæˆåˆå§‹å’Œç»“æŸçŠ¶æ€..."):
            generated_states: GeneratedStates = await state_generation_chain.ainvoke({})
            st.session_state.initial_state = generated_states.initial_state
            st.session_state.final_state = generated_states.final_state

        if st.session_state.initial_state and st.session_state.final_state:
            with st.spinner("æ­£åœ¨ç”Ÿæˆå¼•å¯¼é—®é¢˜..."):
                questions_data: GuidedQuestions = await guiding_questions_chain.ainvoke({
                    "initial_state": st.session_state.initial_state,
                    "final_state": st.session_state.final_state
                })
                st.session_state.guided_questions = questions_data.questions
                # åˆå§‹åŒ–ç”¨æˆ·çš„é€‰æ‹©å­—å…¸çš„keyï¼Œç¡®ä¿åç»­èƒ½ç›´æ¥èµ‹å€¼
                for i in range(len(st.session_state.guided_questions)):
                    st.session_state.user_choices[f"user_choice_{i}"] = None 
                st.session_state.questions_generated = True
        else:
            st.error("æœªèƒ½æˆåŠŸç”Ÿæˆåˆå§‹æˆ–ç»“æŸçŠ¶æ€ï¼Œè¯·é‡è¯•ã€‚")

    except Exception as e:
        st.error(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        st.session_state.questions_generated = False

async def generate_the_final_story():
    """æ ¹æ®ç”¨æˆ·é€‰æ‹©ç”Ÿæˆæœ€ç»ˆå‰§æœ¬"""
    if not st.session_state.initial_state or not st.session_state.final_state or not st.session_state.user_choices:
        st.warning("è¯·å…ˆç”Ÿæˆåˆå§‹è®¾å®šå¹¶å›ç­”æ‰€æœ‰é—®é¢˜ã€‚")
        return

    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å›ç­”æ‰€æœ‰é—®é¢˜ (ç®€å•çš„æ£€æŸ¥æ–¹å¼ï¼Œå¯ä»¥æ ¹æ®éœ€è¦å®Œå–„)
    # GuidedQuestions å›ºå®šä¸º5ä¸ªé—®é¢˜
    if len(st.session_state.user_choices) < 5 or any(v is None for v in st.session_state.user_choices.values()):
        # ç¡®ä¿guided_questions ä¹Ÿè¢«æ­£ç¡®åŠ è½½äº†
        if len(st.session_state.guided_questions) == 5 and len(st.session_state.user_choices) < len(st.session_state.guided_questions):
            st.warning("è¯·å›ç­”æ‰€æœ‰çš„å¼•å¯¼é—®é¢˜åå†ç”Ÿæˆå‰§æœ¬ã€‚")
            return
        elif any(st.session_state.user_choices.get(f"user_choice_{i}") is None for i in range(len(st.session_state.guided_questions))):
             st.warning("è¯·å›ç­”æ‰€æœ‰çš„å¼•å¯¼é—®é¢˜åå†ç”Ÿæˆå‰§æœ¬ã€‚")
             return

    try:
        with st.spinner("æ­£åœ¨èåˆæ‚¨çš„é€‰æ‹©ï¼Œåˆ›ä½œæœ€ç»ˆå‰§æœ¬..."):
            choices_for_prompt = {
                f"user_choice_{i}": st.session_state.user_choices.get(f"user_choice_{i}", "[æœªé€‰æ‹©]") 
                for i in range(len(st.session_state.guided_questions)) # ä½¿ç”¨å®é™…é—®é¢˜æ•°é‡
            }
            payload = {
                "initial_state": st.session_state.initial_state,
                "final_state": st.session_state.final_state,
                **choices_for_prompt
            }
            final_story_data: FinalStory = await story_generation_chain.ainvoke(payload)
            st.session_state.final_story = final_story_data.story
            st.session_state.story_generated = True
            st.balloons() # åº†ç¥ä¸€ä¸‹
    except Exception as e:
        st.error(f"ç”Ÿæˆæœ€ç»ˆå‰§æœ¬æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# --- æŒ‰é’®å’Œç•Œé¢å¸ƒå±€ ---
col_button1, col_button2 = st.columns(2)

with col_button1:
    if st.button("âœ¨ ç”Ÿæˆå‰§æœ¬åˆå§‹è®¾å®š", type="primary", use_container_width=True, disabled=st.session_state.questions_generated and not st.session_state.story_generated):
        asyncio.run(generate_states_and_questions())

with col_button2:
    # åªæœ‰åœ¨é—®é¢˜ç”Ÿæˆåä¸”æ•…äº‹å°šæœªç”Ÿæˆæ—¶ï¼Œæ‰å¯ç”¨ç”Ÿæˆæœ€ç»ˆå‰§æœ¬æŒ‰é’®
    if st.button("ğŸ“œ ç”Ÿæˆæœ€ç»ˆå‰§æœ¬", type="primary", use_container_width=True, disabled=not st.session_state.questions_generated or st.session_state.story_generated):
        asyncio.run(generate_the_final_story())

if st.session_state.story_generated: # æä¾›ä¸€ä¸ªé‡æ–°å¼€å§‹çš„é€‰é¡¹
    if st.button("ğŸ”„ é‡æ–°å¼€å§‹ä¸€æ®µæ–°å†’é™©", use_container_width=True):
        # é‡ç½®æ‰€æœ‰ç›¸å…³çŠ¶æ€ä»¥é‡æ–°å¼€å§‹
        st.session_state.initial_state = ""
        st.session_state.final_state = ""
        st.session_state.guided_questions = []
        st.session_state.user_choices = {}
        st.session_state.final_story = ""
        st.session_state.story_generated = False
        st.session_state.questions_generated = False
        st.rerun() # é‡æ–°è¿è¡Œè„šæœ¬ä»¥åˆ·æ–°ç•Œé¢

if st.session_state.questions_generated and not st.session_state.story_generated:
    st.subheader("ğŸš€ ä½ çš„å†’é™©èµ·ç‚¹å’Œå¯èƒ½çš„ç»ˆç‚¹ï¼š")
    col1, col2 = st.columns(2)
    with col1:
        st.info(f"**åˆå§‹çŠ¶æ€:** {st.session_state.initial_state}")
    with col2:
        st.warning(f"**ç»“æŸçŠ¶æ€:** {st.session_state.final_state}")

    st.subheader("ğŸ—ºï¸ è¯·é€šè¿‡ä»¥ä¸‹é—®é¢˜å¼•å¯¼å‰§æœ¬åˆ›ä½œï¼š")
    
    for i, q_item in enumerate(st.session_state.guided_questions):
        question_text = f"{i+1}. {q_item.question}"
        options = [opt for opt in q_item.options]
        choice_key = f"user_choice_{i}"
        
        # ä» session_state è·å–å½“å‰ä¸ºæ­¤é—®é¢˜ä¿å­˜çš„ç­”æ¡ˆ
        current_choice_val = st.session_state.user_choices.get(choice_key)
        current_choice_idx = options.index(current_choice_val) if current_choice_val in options else 0

        selected_option = st.radio(
            question_text,
            options,
            key=f"radio_{choice_key}", # ç¡®ä¿keyæ˜¯å”¯ä¸€çš„ï¼Œå¹¶ä¸”åœ¨é‡æ–°ç”Ÿæˆé—®é¢˜æ—¶èƒ½æ­£ç¡®æ›´æ–°
            index=current_choice_idx,
        )
        st.session_state.user_choices[choice_key] = selected_option

if st.session_state.story_generated and st.session_state.final_story:
    st.subheader("ğŸ‰ æ­å–œï¼ä½ çš„å†’é™©å‰§æœ¬å·²ç”Ÿæˆï¼š")
    st.markdown(st.session_state.final_story)
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½å‰§æœ¬ (.txt)",
        data=st.session_state.final_story,
        file_name="æˆ‘çš„å†’é™©å‰§æœ¬.txt",
        mime="text/plain"
    )


# æ·»åŠ ä¸€äº›è¯´æ˜å’Œé¡µè„š
st.markdown("---")
st.markdown("ç”± Langchain å’Œ Streamlit é©±åŠ¨ | ä¸€ä¸ªAIå‰§æœ¬å°åŠ©æ‰‹")